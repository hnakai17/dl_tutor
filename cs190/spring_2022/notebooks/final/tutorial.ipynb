{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Congratulations! You have reached the end of the CS 190 curriculum. As a final summative exercise, you will be tasked to develop a model to differentiate between kidneys with tumor from those that are normal using any of the approaches and tools you have learned this quarter. The brief tutorial will simply introduce the dataset and provide some strategies to help guide exploration. Once you are familiar with the task, you are welcome to move onto the assignment which contains more details regarding algorithm design requirements and submission.\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about the KiTS Challenge can be found here: https://kits21.kits-challenge.org/. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='ct/kits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality. As needed, pass any custom configurations (e.g. batch size, normalization parameters, etc) into the optional `configs` dictionary argument. \n",
    "\n",
    "In this exercise, we will be using abdominal CT volumes that have been preprocessed into 96 x 96 x 96 matrix volumes, each cropped to the right and left kidney, facilitating ease of algorithm training within the Google Colab platform. Based on model implementation strategy, both 2D and 3D data have been prepared for this exercise. To specificy the correct Generator template file, pass a designated `keyword` string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2D dataset**: To select the 2D data of input size `(1, 96, 96, 1)` use the keyword `2d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "configs = {'batch': {'size': 16, 'fold': 0}}\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d', configs=configs, custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D dataset**: To select the 3D data of input size `(96, 96, 96, 1)` use the keyword `3d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "configs = {'batch': {'size': 2, 'fold': 0}}\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='3d', configs=configs, custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling\n",
    "\n",
    "As needed, consider stratified sampling to increase and/or decrease the rate at which certain classes are presented to the model during the training process. Recall that a total of three different classes are defined: \n",
    "\n",
    "* class 0: background\n",
    "* class 1: normal kidney\n",
    "* class 2: tumor\n",
    "\n",
    "To change the default sampling strategy, pass a distribution of sampling rates in the `sampling` entry within the `configs` dictioary:\n",
    "\n",
    "```python\n",
    "# --- Prepare configs dict\n",
    "configs = {\n",
    "    'batch': {'size': ...},\n",
    "    'sampling': {\n",
    "        'lbl-crp-00': 0.4,\n",
    "        'lbl-crp-01': 0.3,\n",
    "        'lbl-crp-02': 0.3}}\n",
    "        \n",
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d', configs=configs, custom_layers=True)\n",
    "        \n",
    "```\n",
    "\n",
    "See details presented in Week 8 (Class Imbalance) for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD5ejoTbx1_0"
   },
   "source": [
    "### KITS Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to visualize using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show the first example\n",
    "xs, _ = next(gen_train)\n",
    "imshow(xs['dat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kidney masks\n",
    "\n",
    "The ground-truth labels are three class masks of the same matrix shape as the model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xs['lbl'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `imshow(...)` method to visualize the ground-truth tumor mask labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show tumor masks overlaid on original data\n",
    "imshow(xs['dat'], xs['lbl'])\n",
    "\n",
    "# --- Show tumor masks isolated\n",
    "imshow(xs['lbl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator\n",
    "\n",
    "In this final project, both classification and segmentation models will be evaluated. Depending on preference, either 2D and/or 3D models may be created. Additionally, while three total classes are available for use during the training process, all models will produce a binary prediction result (tumor vs. no tumor). \n",
    "\n",
    "To accomodate these various permutations, consider the following custom code to implement a nested generator strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(gen, dims=2, task='cls', binarize=True):\n",
    "    \"\"\"\n",
    "    Custom generator to modify raw labels for 2D/3D classification or segmentation tasks\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (generator) gen      : original unmodified generator\n",
    "      (int)       dims     : 2D or 3D model\n",
    "      (str)       task     : 'cls' or 'seg' \n",
    "      (bool)      binarize : whether or not to binarize original 3-class labels\n",
    "    \n",
    "    \"\"\"\n",
    "    assert task in ['cls', 'seg']\n",
    "\n",
    "    for xs, _ in gen:\n",
    "\n",
    "        # --- Convert segmentation into classification labels\n",
    "        if task == 'cls':\n",
    "            axis = (2, 3, 4) if dims == 2 else (1, 2, 3, 4)\n",
    "            xs['lbl'] = np.max(xs['lbl'], axis=axis, keepdims=True)\n",
    "            \n",
    "        # --- Binarize\n",
    "        if binarize:\n",
    "            xs['lbl'] = xs['lbl'] == 2\n",
    "\n",
    "        yield xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### Blocks\n",
    "\n",
    "To facilitate development of either 2D or 3D models, consider the following generic code template for creating 2D or 3D blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blocks(dims=2):\n",
    "    \n",
    "    kernel_size = (1, 3, 3) if dims == 2 else (3, 3, 3)\n",
    "    strides = (1, 2, 2) if dims == 2 else (2, 2, 2)\n",
    "    \n",
    "    # --- Define kwargs\n",
    "    kwargs = {\n",
    "        'kernel_size': kernel_size,\n",
    "        'padding': 'same',\n",
    "        'kernel_initializer': 'he_normal'}\n",
    "\n",
    "    # --- Define block components\n",
    "    conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "    tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "\n",
    "    norm = lambda x : layers.BatchNormalization()(x)\n",
    "    relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "    conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "    conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=strides)))\n",
    "    tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=strides)))\n",
    "\n",
    "    concat = lambda a, b : layers.Concatenate()([a, b])\n",
    "                                     \n",
    "    return conv1, conv2, tran2, concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses\n",
    "\n",
    "For both classification and segmentation tasks, the default loss function of choice is standard softmax cross-entropy:\n",
    "\n",
    "```python\n",
    "sce = losses.SparseCategoricalCrossentropy(from_logits=True)(\n",
    "    y_true=inputs['lbl'],\n",
    "    y_pred=logits)\n",
    "```\n",
    "\n",
    "To emphasize the foreground (tumor) class, consider either **weighted** loss functions and/or focal loss. Again, these strategies may be applied to both the classification and segmentation tasks. See Week 8 (Class Imbalance) for further details.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "For the classification task, the default metric of choice is accuracy:\n",
    "\n",
    "```python\n",
    "acc = metrics.sparse_categorical_accuracy(\n",
    "    y_true=inputs['lbl'], \n",
    "    y_pred=logits)\n",
    "```\n",
    "\n",
    "For the segmentation task, the default metric of choice is Dice score.\n",
    "\n",
    "```python\n",
    "def calculate_dsc(y_true, y_pred, weights=None, c=1):\n",
    "    \"\"\"\n",
    "    Method to calculate the Dice score coefficient for given class\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      y_true : ground-truth label\n",
    "      y_pred : predicted logits scores\n",
    "           c : class to calculate DSC on\n",
    "    \n",
    "    \"\"\"    \n",
    "    true = y_true[..., 0] == c\n",
    "    pred = tf.math.argmax(y_pred, axis=-1) == c \n",
    "    \n",
    "    if weights is not None:\n",
    "        true = true & (weights[..., 0] != 0)\n",
    "        pred = pred & (weights[..., 0] != 0)\n",
    "\n",
    "    A = tf.math.count_nonzero(true & pred) * 2\n",
    "    B = tf.math.count_nonzero(true) + tf.math.count_nonzero(pred)\n",
    "    \n",
    "    return tf.math.divide_no_nan(\n",
    "        tf.cast(A, tf.float32), \n",
    "        tf.cast(B, tf.float32))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "The first task is to create any classification model for binary tumor detection. A 2D model will predict tumor vs. no tumor on a slice-by-slice basis whereas a 3D model will predict tumor vs. no tumor on a volume basis. Regardless of implementation choice, all statistical analysis will be performed on a **volume basis**. For those that choose a 2D model, a reduction strategy must be implemented (see details further below).\n",
    "\n",
    "An example simple 2D backbone implementation may be defined as follows:\n",
    "\n",
    "```python\n",
    "# --- Define model input \n",
    "x = Input(shape=(None, 96, 96, 1), dtype='float32')\n",
    "\n",
    "# --- Define layers\n",
    "l1 = conv1(8, x)\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))\n",
    "l6 = conv1(80, conv2(80, l5))\n",
    "\n",
    "# --- Reshape\n",
    "f0 = layers.Reshape(...)(l6)\n",
    "\n",
    "# --- Create logits\n",
    "...\n",
    "```\n",
    "\n",
    "See details presented in Weeks 3 and 4 for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "The second task is to create any segmentation model for binary tumor localization. A 2D model will predict tumor segmentation masks on a slice-by-slice basis whereas a 3D model will predict tumor segmentation masks on a volume basis. Regardless of implementation choice, all statistical analysis will be performed on a **volume basis**. To do so, a reduction strategy must be implemented (see details further below).\n",
    "\n",
    "An example simple 2D backbone U-Net implementation may be defined as follows:\n",
    "\n",
    "```python\n",
    "# --- Define model input \n",
    "x = Input(shape=(None, 96, 96, 1), dtype='float32')\n",
    "\n",
    "# --- Define contracting layers\n",
    "l1 = conv1(8, x)\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))\n",
    "\n",
    "# --- Define expanding layers\n",
    "l6  = tran2(48, l5)\n",
    "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
    "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
    "l9  = tran2(8,  conv1(16, concat(l2, l8)))\n",
    "l10 = conv1(8,  l9)\n",
    "\n",
    "# --- Create logits\n",
    "...\n",
    "```\n",
    "\n",
    "See details presented in Weeks 5 for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction Strategies\n",
    "\n",
    "Regardless of implementation strategy, the final goal of all models in this project is to produce a single binary classification result for tumor vs. no tumor on a per volume basis. Aside from a 3D binary classification model, all other implementations must define a **reduction strategy** to collapse multiple predictions into just a single global per-volume prediction.\n",
    "\n",
    "The following examples demonstrate expected predictions for any given single `96 x 96 x 96 x 1` volume:\n",
    "\n",
    "* 2D classification model: 96 predictions (one per slice)\n",
    "* 2D or 3D segmentation models: 96 ** 3 predictions\n",
    "\n",
    "### Reduction\n",
    "\n",
    "The first step in a reduction strategy is to define a single aggregate per exam **score** based on the available predictions. One simple implementation is to add together all binarized predictions. Alternatives include various statistical metrics derived from softmax-transformed logit scores.\n",
    "\n",
    "The following code block demonstrates how to calculate an aggregate summed score across all validation exams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "test_train = G(test_train, dims=2, task='cls')\n",
    "test_valid = G(test_valid, dims=2, task='cls')\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "for x in test_valid:\n",
    "    \n",
    "    # --- Aggregate preds\n",
    "    pred = backbone.predict(x['dat'])\n",
    "    preds.append(np.argmax(pred, axis=-1).sum())\n",
    "\n",
    "    # --- Aggregate trues\n",
    "    trues.append(x['lbl'].any())\n",
    "\n",
    "# --- Create Numpy arrays\n",
    "preds = np.array(preds)\n",
    "trues = np.array(trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds\n",
    "\n",
    "To convert the raw reduction score into a prediction, consider application of various thresholds. Assuming that approximately half of the predictions need to be positive (tumor), consider using the mean or median prediction as a first-pass threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Apply threshold\n",
    "thresh = np.median(preds)\n",
    "preds_ = preds >= thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code cell to calculate accuracy, sensitivity, specificity, PPV and NPV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate TP/TN/FN/FP\n",
    "corr = preds_ == trues\n",
    "tp = np.sum(corr & trues)\n",
    "tn = np.sum(corr & ~trues)\n",
    "fn = np.sum(~corr & trues)\n",
    "fp = np.sum(~corr & ~trues)\n",
    "\n",
    "# --- Calculate stats\n",
    "acc = (tp + tn) / corr.size\n",
    "sen = tp / (tp + fn)\n",
    "spe = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "print('Acc: {:0.4f}'.format(acc))\n",
    "print('Sen: {:0.4f}'.format(sen))\n",
    "print('Spe: {:0.4f}'.format(spe))\n",
    "print('PPV: {:0.4f}'.format(ppv))\n",
    "print('NPV: {:0.4f}'.format(npv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you automate the above to test various different thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips\n",
    "\n",
    "To create the overall best model, consider the following.\n",
    "\n",
    "### Classification\n",
    "\n",
    "For classification models, consider using the advanced motifs described in Week 4. \n",
    "\n",
    "* residual connection\n",
    "* bottleneck operation\n",
    "* Inception module\n",
    "* Squeeze-and-Excite (SE) module\n",
    "\n",
    "### Segmentation\n",
    "\n",
    "For segmentation models, consider using the advanced motifs described in Week 5 and the midterm.\n",
    "\n",
    "* deep supervision\n",
    "* residual skip connections\n",
    "* multiple skip operations\n",
    "\n",
    "### Alternative models\n",
    "\n",
    "* box localization networks (Week 7)\n",
    "* unsupervised pretraining (Week 9)\n",
    "\n",
    "### Loss \n",
    "\n",
    "Masked and/or weighted loss functions are likely to produce the best results on this task. To use these strategies, do *not* binarize the raw data e.g., `G(..., binarize=False)`. Use the different classes to create customized `sample_weight` tensors, but ensure that the final ground-truth label is binarized manually before passing into the loss function. Additionally, during the inference loop, ensure that the necessary modifications are applied to model predictions (e.g., mask out portions of your prediction that are masked during algorithm training).\n",
    "\n",
    "See Week 8 for further details.\n",
    "\n",
    "### Data augmentation\n",
    "\n",
    "Consider the following code block to implement data augmentation:\n",
    "\n",
    "```python\n",
    "def augmentation(inputs, factor=0.2):\n",
    "\n",
    "    kwargs = {\n",
    "        'interpolation': 'nearest',\n",
    "        'fill_mode': 'constant',\n",
    "        'fill_value': 0.0}\n",
    "\n",
    "    a = layers.Concatenate()((inputs['dat'], inputs['lbl']))\n",
    "    a = tf.reshape(a, (-1, 96, 96, 2))\n",
    "    a = layers.experimental.preprocessing.RandomRotation(factor=factor, **kwargs)(a)\n",
    "    a = layers.experimental.preprocessing.RandomTranslation(factor, factor, **kwargs)(a)\n",
    "    a = layers.experimental.preprocessing.RandomZoom(factor, **kwargs)(a)\n",
    "    a = tf.reshape(a, (inputs['dat'].shape[0], inputs['dat'].shape[1], 96, 96, 2)) \n",
    "\n",
    "    x = a[..., 0:1]\n",
    "    y = a[..., 1:2]\n",
    "\n",
    "    return x, y\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
