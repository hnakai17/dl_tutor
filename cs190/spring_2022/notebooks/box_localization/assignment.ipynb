{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment we will train a box localization algorithm derived from RetinaNet to perform kidney localization onCT. The algorithm will be implemented using a feature pyramid network backbone. Accuracy will be calculated based on median IoU performance against ground-truth masks.\n",
    "\n",
    "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "Once complete, the following items must be submitted:\n",
    "\n",
    "* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/cnn/assignment.ipynb)\n",
    "* final trained `*.hdf5` model file\n",
    "* final compiled `*.csv` file with performance statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, models, layers, optimizers\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow\n",
    "from jarvis.train.box import BoundingBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about he KiTS Challenge can be found here: https://kits21.kits-challenge.org/. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code will:\n",
    "\n",
    "1. Download the dataset (if not already present) \n",
    "2. Prepare the necessary Python generators to iterate through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='ct/kits')\n",
    "\n",
    "# --- Prepare generators and model inputs\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d-bin', custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "In this assignment we will train a box localization network for kidney detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define box parameters\n",
    "\n",
    "Use the following cell block to define your `BoundingBox` object as discussed in the tutorial. Feel free to optimize hyperparameter choices for grid size, anchor shapes, anchor aspect ratios, and anchor scales: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = BoundingBox(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inputs\n",
    "\n",
    "Use the following cell block to define the nested generators needed to convert raw masks into bounding box ground-truth predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_generator(G):\n",
    "    \n",
    "    for xs, _ in G:\n",
    "        \n",
    "        # --- Convert mask into bounding-box paramaterization\n",
    "        msk = xs.pop('lbl')\n",
    "        box = bb.convert_msk_to_box(msk=msk)\n",
    "        \n",
    "        # --- Update xs dictionary\n",
    "        xs.update(box)\n",
    "        \n",
    "        yield xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid = client.create_generators()\n",
    "gen_train = box_generator(G=gen_train)\n",
    "gen_valid = box_generator(G=gen_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define backbone model\n",
    "\n",
    "Use the following cell block to define your feature pyramid network backbone and RetinaNet classification / regression networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define input\n",
    "x = Input(shape=?, dtype='float32')\n",
    "\n",
    "# --- Define model\n",
    "\n",
    "# --- Define logits\n",
    "logits = ...\n",
    "\n",
    "# --- Create model\n",
    "backbone = Model(inputs=x, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training model\n",
    "\n",
    "Recall the following requirements as described in the tutorial:\n",
    "\n",
    "* use of a focal sigmoid (binary) cross-entropy loss function for regression\n",
    "* use of a Huber loss function for classification\n",
    "* use of masked loss functions to ensure only relevant examples are used for training\n",
    "* use of appropriate metrics to track algorithm training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define inputs\n",
    "inputs = {?}\n",
    "\n",
    "# --- Define model\n",
    "logits = backbone(inputs['dat'])\n",
    "\n",
    "# --- Define loss\n",
    "\n",
    "# --- Define metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to create the `training` model and add the corresponding loss and accuracy tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model\n",
    "training = Model(inputs=inputs, outputs=?)\n",
    "\n",
    "# --- Add loss\n",
    "\n",
    "# --- Add metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "\n",
    "Use the following cell block to compile your model with an appropriate optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory data\n",
    "\n",
    "To speed up training, consider loading all your model data into RAM memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Use the following cell block to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Based on the tutorial discussion, use the following cells to calculate model performance. The following metrics should be calculated:\n",
    "\n",
    "* median IoU\n",
    "* 25th percentile IoU\n",
    "* 75th percentile IoU\n",
    "\n",
    "### Performance\n",
    "\n",
    "The following minimum performance metrics must be met for full credit:\n",
    "\n",
    "* median IoU: >0.50\n",
    "* 25th percentile IoU: >0.40\n",
    "* 75th percentile IoU: >0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "test_train = box_generator(test_train)\n",
    "test_valid = box_generator(test_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "When ready, create a `*.csv` file with your compiled **validation** cohort IoU statistics. There is no need to submit training performance accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "backbone.save('./model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canvas\n",
    "\n",
    "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
    "\n",
    "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
    "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
    "* final (trained) model: `[UCInetID]_model.hdf5`\n",
    "\n",
    "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
