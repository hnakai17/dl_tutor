{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will review key modern CNN architecture motifs and discuss implementation strategies using Tensorflow 2 / Keras.\n",
    "\n",
    "**Modern Architectures**\n",
    "\n",
    "* residual connection\n",
    "* bottleneck operation\n",
    "* Inception module\n",
    "* Squeeze-and-Excite (SE) module\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about he KiTS Challenge can be found here: https://kits21.kits-challenge.org/. In this exercise, we will use this dataset to derive a model for slice-by-slice kidney detection. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='ct/kits-128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality. As needed, pass any custom configurations (e.g. batch size, normalization parameters, etc) into the optional `configs` dictionary argument. \n",
    "\n",
    "To specificy the correct Generator template file, pass a designated `keyword` string. In this tutorial, we will be using abdominal CT volumes that have been preprocessed into 128 x 128 matrix images, each derived from a *mean intensity projection* (MeanIP) algorithm to approximately 5 mm in slice thickness, facilitating ease of algorithm training within the Google Colab platform. To select the correct Client template for this task, use the keyword string `128*cls`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits-128', keyword='128*glb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created generators yield a total of `batch['size']` training samples based on the specified batch size. As before, each iteration yields dictionary of model inputs, `xs`. In the current example, there is just a single input image `xs['dat']` and a single target `xs['lbl']`. Let us examine the generator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, _ = next(gen_train)\n",
    "\n",
    "# --- Print dict keys\n",
    "for k, v in xs.items():\n",
    "    print('key = {} : shape = {}'.format(k.ljust(7), v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD5ejoTbx1_0"
   },
   "source": [
    "### KITS Data\n",
    "\n",
    "The input images in the variable `dat` are matrices of shape `1 x 128 x 128 x 1`. Note that even though the images here are 2D in shape, the full matrix is a 3D tensor `(z, y, x)` where `z = 1` in this implementation. Note that although the 3rd z-axis dimension is redundant here (for a single slice input), many of our more complex models and architectures will commonly require a full 3D tensor. Because of this, we will directly use 3D convolutions throughout the tutorial materials for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to visualize using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show the first example\n",
    "imshow(xs['dat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `montage(...)` function to create an N x N mosaic of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show \"montage\" of all images\n",
    "imshow(xs['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the `xs['lbl']` vector corresponds to ground-truth, whereby:\n",
    "* class `0`: no kidney\n",
    "* class `1`: kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print xs['lbl']\n",
    "print(xs['lbl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the multiple options for creating a residual connection:\n",
    "\n",
    "![Diagramtric Representation](https://raw.githubusercontent.com/peterchang77/dl_tutor/master/cs190/spring_2022/notebooks/detection/pngs/residual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will recreate the highest performing residual connection implemented using **full pre-activation**. \n",
    "\n",
    "Let us first begin by defining a single `Input` variable `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model input \n",
    "x = Input(shape=(None, 128, 128, 1), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the prior tutorial, let us set up the same lambda functions for CNN definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of our standard block, let us define a **full pre-activation** block instead:\n",
    "\n",
    "* `[ conv - norm - relu ]` ==> original (standard) \n",
    "* `[ norm - relu - conv ]` ==> full pre-activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : conv(relu(norm(x)), filters, strides=1)\n",
    "conv2 = lambda filters, x : conv(relu(norm(x)), filters, strides=(1, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To seed a **full pre-activation** ResNet, start by applying a naive convolution (no activation) to the first input layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- First standard conv layer\n",
    "l0 = conv(x, filters=16, strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining network blocks, implementation of a residual function is straightforward as recent versions of Tensorflow / Keras layers can utilize the native Python addition `+` operator directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, l0)\n",
    "l2 = conv1(16, l1)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(16, l2) + l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "\n",
    "Note that layers can added **only if** the layer sizes match exactly. What happens if the total number of feature maps (e.g. layer depth) is different? The solution is use of the `1 x 1` projection matrix (e.g. convolutional operation without corresponding nonlinearity). Here the third and fourth dimension of the convolutional kernel are designed to match the number of channels in the input and target output tensors, respectively:\n",
    "\n",
    "```\n",
    "filter size = I x J x C0 x C1\n",
    "\n",
    "I  ==> 1\n",
    "J  ==> 1\n",
    "C0 ==> # of channels in input tensor\n",
    "C1 ==> # of channels in output tensor\n",
    "```\n",
    "\n",
    "Recall that in Tensorflow, only the output layer channel size needs to be defined (the third channel of the convolutional kernel is inferred based on the input tensor). Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, l0)\n",
    "l2 = conv1(32, l1)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) # + l1 would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `l1` cannot be added since dimensions do not match. Thus consider the following projection operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) + proj(32, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about differences not only in channel depth but also feature map size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, l0)\n",
    "l2 = conv2(32, l1)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) # + l1 would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the subsample operation, the projection operation now also must strided as well. Given this, it may be useful to increase the `kernel_size` of the project operation as you recall so that all activations are contributing to the output projection tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=(1, 2, 2), \n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) + proj(32, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck\n",
    "\n",
    "![Bottleneck](https://raw.githubusercontent.com/peterchang77/dl_tutor/master/cs190/spring_2022/notebooks/detection/pngs/bottleneck.png)\n",
    "\n",
    "Bottleneck operations are used to decrease the total number of feature maps (filters) for convolutional efficiency. They are similar to projection operations in that both utilize a `1 x 1 x 1` convolutional kernel, however a bottleneck operation includes a nonlinearity term e.g., it is defined as a full convolutional *block*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "bneck = lambda filters, x : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding='same')(relu(norm(x)))\n",
    "\n",
    "# --- Define standard conv-conv block\n",
    "l1 = conv1(32, l0)\n",
    "l2 = conv1(32, l1)\n",
    "\n",
    "# --- Define bottleneck conv-conv block\n",
    "l1 = conv1(32, l0)\n",
    "l2 = bneck(32, conv1(8, bneck(8, l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the computational efficiency of the bottleneck vs. the standard conv block in this example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of an Inception module:\n",
    "\n",
    "![Inception](https://raw.githubusercontent.com/peterchang77/dl_tutor/master/cs190/spring_2021/notebooks/detection/pngs/inception.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first implement a naive Inception module without any bottlenecks. Recall that we will need four different paths implemented:\n",
    "\n",
    "* 1x1 convolution\n",
    "* 3x3 convolution\n",
    "* 5x5 convolution\n",
    "* 3x3 max-pool\n",
    "\n",
    "Let us define these building blocks with the following lambda functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define lambda functions\n",
    "conv = lambda x, filters,kernel_size : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    kernel_size=kernel_size, \n",
    "    padding='same')(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define 1x1, 3x3, 5x5 convs and 3x3 pools\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 1, 1))))\n",
    "conv3 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 3, 3))))\n",
    "conv5 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 5, 5))))\n",
    "mpool = lambda x : layers.MaxPool3D(pool_size=(1, 3, 3), strides=1, padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above implementation, max-pooling is used as a standard layer without any subsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use these lambda functions to create a test Inception module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first layer operation\n",
    "l1 = conv3(16, x)\n",
    "\n",
    "# --- Define four different paths\n",
    "filters = 16\n",
    "p1 = conv1(filters, l1)\n",
    "p2 = conv3(filters, l1)\n",
    "p3 = conv5(filters, l1)\n",
    "p4 = mpool(l1)\n",
    "\n",
    "# --- Concatenate\n",
    "l2 = layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, naive implementation of the Inception module yields large channel depths over time. To avoid this, use bottleneck operations. In the current code blocks, note that the `conv1` lambda function e.g., 1 x 1 convolution, can be used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first layer operation\n",
    "l1 = conv3(16, x)\n",
    "\n",
    "# --- Define four different paths\n",
    "filters = 4\n",
    "p1 = conv1(filters, l1)\n",
    "p2 = conv3(filters, conv1(filters, l1))\n",
    "p3 = conv5(filters, conv1(filters, l1))\n",
    "p4 = conv1(filters, mpool(l1))\n",
    "\n",
    "# --- Concatenate\n",
    "l2 = layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze-and-Excite\n",
    "\n",
    "Recall the definition of a squeeze-and-excite module:\n",
    "\n",
    "![SENet](https://pbs.twimg.com/media/DO25715W0AAxIKA.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE Module\n",
    "\n",
    "The SE module is a simple modification that can be applied to any existing architecture. Starting with the output of any standard convolutional block (e.g., convolution and activation function), the intermediate feature map is scaled by a constant value independently across all channels to *emphasize* the important features for any given single image (or volume). The scaling values are learned via an SE block, which is characterized by several key features:\n",
    "\n",
    "```\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "```\n",
    "\n",
    "* **squeeze**: collapse of N x N feature maps to 1 x 1 feature vectors via global pooling\n",
    "* **excitation**: two fully connected layers to model channel-wise (feature-wise) interdependencies\n",
    "* **scale**: scaling all feature maps by the learned *excitation* values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start this implementation by creating a first layer feature map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "\n",
    "# --- Define model\n",
    "l1 = conv1(32,  x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to modify the output feature map `l1` by a scalar vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Squeeze (global pool)\n",
    "sqz = layers.AveragePooling3D((1, l1.shape[2], l1.shape[3]))(l1)\n",
    "\n",
    "# --- Excitation (reduce channels to 1 / R) ==> in this example set R = 4 arbitrarily\n",
    "cha = int(p1.shape[-1] / 4)\n",
    "exc = layers.Conv3D(filters=filters, kernel_size=1, activation='relu')(sqz)\n",
    "\n",
    "# --- Scale (expand channels to original size)\n",
    "sca = layers.Conv3D(filters=l1.shape[-1], kernel_size=1, activation='sigmoid')(exc)\n",
    "\n",
    "# --- Modify l1\n",
    "l1 = l1 * sca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `l1` has been modified, it can be passed to the next layer exactly as before (e.g., with another `conv1(...)` or `conv2(...)` operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models\n",
    "\n",
    "Let us compile a temporary model for purposes of demontrating evaluation procedure. Note that in this example, no special motifs are used.\n",
    "\n",
    "## Backbone model\n",
    "\n",
    "Using the concepts introduced above, let us start by recreating the base `backbone` model (e.g., without training dependencies). Use the following line of code to create the `backbone` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define convolution parameters\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model\n",
    "l1 = conv1(32,  x)\n",
    "l2 = conv1(48,  conv2(48,  l1))\n",
    "l3 = conv1(64,  conv2(64,  l2))\n",
    "l4 = conv1(80,  conv2(80,  l3))\n",
    "l5 = conv1(96,  conv2(96,  l4))\n",
    "l6 = conv1(128, conv2(128, l5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition from CNN to MLP\n",
    "\n",
    "At this point of the model, to convert from CNN to MLP architecture, the `(1, N, N, C)` feature maps need to be collapsed into vector form. A `layers.Flatten()` operation may accomplish this by converting our feature map to a single `(1 * N * N * C,)` vector. An alternative to this is to use a `layers.Reshape()` operation to convert our feature map to a `(1, 1, 1, N * N * C)` feature map; subsequently, any additional 3D convolutional operation with kernel size `(1, 1, 1, C-in, C-out)` will be **identical** to a matrix multiply operation.\n",
    "\n",
    "In other words:\n",
    "\n",
    "```\n",
    "input          | output                | output type    | downstream matrix multiply operations\n",
    "---------------------------------------------------------------------------------------------------\n",
    "(1, N, N, C)   | (N * N * C,)          | vector         | layers.Dense(...)\n",
    "(1, N, N, C)   | (1, 1, 1, N * N * C)  | feature map    | layers.Conv3D(filters=...)\n",
    "```\n",
    "\n",
    "In this implementation (and all other tutorial examples) we will use the second option using `layers.Reshape(...)`. The rationale is that while we are currently training with 2D input slices of shape `(1, 240, 240)`, once the model is trained we would like to pass any volume of arbitrary size into the model (e.g., many slices). A global `layers.Flatten()` operation will convert the entire 3D volume into a vector without preserving slice-by-slice information. A `layers.Reshape([-1, 1, 1, N * N * C])` operation however will be able to flexibly handle arbirary shapes.\n",
    "\n",
    "Fo example, let us assume we have an input with z- number of slices:\n",
    "\n",
    "```\n",
    "input          | operation                               | output\n",
    "---------------------------------------------------------------------------------------------------\n",
    "(Z, N, N, C)   | layers.Flatten()                        | (Z * N * N * C,)\n",
    "(Z, N, N, C)   | layers.Reshape([-1, 1, 1, N * N * C])   | (Z, 1, 1, N * N * C)\n",
    "```\n",
    "\n",
    "The output of the `layers.Flatten()` operation is a single vector (e.g., all slices are collapsed). By contrast, the output of the `layers.Reshape(...)` operation by contrast allows for a total of `z` feature vectors each of shape `N * N * C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract shape and reshape\n",
    "n0, n1, c = l6.shape[-3:]\n",
    "f0 = layers.Reshape([-1, 1, 1, n0 * n1 * c])(l6)\n",
    "\n",
    "# --- Create logits\n",
    "logits = layers.Conv3D(filters=2, kernel_size=1)(f0)\n",
    "\n",
    "# --- Create model\n",
    "backbone = Model(inputs=x, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `backbone` model architecture is wrapped in a second model with additional layer(s) that define optimization behavior including loss function derivations.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "As before, we start by defining all `inputs` into our new *wrapper* model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'dat': Input(shape=(1, 128, 128, 1), name='dat'),\n",
    "    'lbl': Input(shape=(1, 1, 1, 1), name='lbl')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this `inputs` Python dictionary, let us first recreate the CNN model operations by **reusing** the `backbone` object that we already defined. Doing so means that our new *wrapper* model is explicitly derived from the `backbone`. Any updates applied to our new *wrapper* model are propogated to the `backbone` model and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first step of new wrapper model\n",
    "logits = backbone(inputs['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a softmax cross-entropy loss in Tensorflow, use the `losses.SparseCategoricalCrossentropy(...)` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define loss object\n",
    "sce = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# --- Create loss tensor\n",
    "loss = sce(y_true=inputs['lbl'], y_pred=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use the TensorFlow built-in method `metrics.sparse_categorical_accuracy(...)` to calculate per-batch accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define accuracy\n",
    "acc = metrics.sparse_categorical_accuracy(y_true=inputs['lbl'], y_pred=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model\n",
    "\n",
    "Now let us create the new wrapper model. The inputs are defined above already in our `inputs` Python dictionary. As outputs, let us return both the `logits` tensor as well as the `loss`. We will name this new wrapper model `training` because it will be used for training only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = Model(inputs=inputs, outputs={'logits': logits, 'loss': loss, 'acc': acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the `loss` and `metric` tensorws we defined above to the new `training` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add loss\n",
    "training.add_loss(loss)\n",
    "\n",
    "# --- Add metric\n",
    "training.add_metric(acc, name='acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model\n",
    "\n",
    " To prepare the model for learning, a graph must be **compiled** with a strategy for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define an Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=2e-4)\n",
    "\n",
    "# --- Compile model\n",
    "training.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "At this point, the model is ready for training using the standard `training.fit(...)` API with our train and valid generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory data\n",
    "\n",
    "For moderate sized datasets which are too large to fit into immediate hard-drive cache, but small enough to fit into RAM memory, it is often times a good idea to first load all training data into RAM memory for increased speed of training. The `client` can be used for this purpose as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=100, \n",
    "    epochs=10,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=100,\n",
    "    validation_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To test the trained model, the following steps are required:\n",
    "\n",
    "* load data\n",
    "* use `model.predict(...)` to obtain logit scores\n",
    "* use `np.argmax(...)` to obtain prediction\n",
    "* compare prediction with ground-truth\n",
    "* serialize in Pandas DataFrame\n",
    "\n",
    "Recall that the generator used to train the model simply iterates through the dataset randomly. For model evaluation, the cohort must instead be loaded manually in an orderly way. For this tutorial, we will create new **test mode** data generators, which will simply load each example individually once for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**: although the model is trained using 2D slices, there is nothing to preclude passing an entire 3D volume through the model at one time (e.g. consider that the entire 3D volume is a single *batch* of data). When the`expand=True` flag is set in the `client.create_generators(...)` method above, one of the of the key generator modifications is to yield entire 3D volumes instead of slices.\n",
    "\n",
    "Note that typically performance metrics for medical imaging models are commonly reported on a volume-by-volume basis (not slice-by-slice). However in this example we will simply be evaluating slice-by-slice performance as each patient in this cohort does in fact have a brain tumor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run entire volume through model\n",
    "x, _ = next(test_train)\n",
    "logits = backbone.predict(x['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the model properly generate a prediction for every slice in the 3D volume? What is the output shape? If you need to review concepts, please reference the discussion above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Code\n",
    "\n",
    "Use the following lines of code to run prediction through the **valid** cohort generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "trues = []\n",
    "preds = []\n",
    "\n",
    "for x, _ in test_valid:\n",
    "    \n",
    "    # --- Predict\n",
    "    logits = backbone.predict(x['dat'])\n",
    "\n",
    "    # --- Argmax\n",
    "    pred = np.squeeze(np.argmax(logits, axis=-1))\n",
    "\n",
    "    trues.append(x['lbl'].ravel())\n",
    "    preds.append(pred.ravel())\n",
    "\n",
    "trues = np.concatenate(trues)\n",
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare results in Pandas DataFrame for ease of analysis and sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create DataFrame\n",
    "df = pd.DataFrame(index=np.arange(preds.size))\n",
    "\n",
    "# --- Define columns\n",
    "df['true'] = trues\n",
    "df['pred'] = preds\n",
    "df['corr'] = df['true'] == df['pred']\n",
    "\n",
    "# --- Print accuracy\n",
    "print(df['corr'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `backbone.save()` and `backbone.load_model()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "backbone.save('./model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del backbone\n",
    "backbone = models.load_model('./model.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Up until this point, this tutorial has presented key implementation details for three advanced CNN motifs: residual operation (with bottleneck); Inception module; Squeeze-and-Excite (SE) module. However the working examples above may become tedious to use in a large network architecture. To facilitate additional organization, consider the following helper methods to generically implement these motifs in various settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a general method to facilitate a residual connection between any arbitrary two tensors. Keep in mind that prior to the addition operation, one needs to account for potential feature map differences in:\n",
    "\n",
    "* feature map size\n",
    "* feature map depth\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(a, b):\n",
    "    \"\"\"\n",
    "    Method to implement residual connection between two arbitrary tensors (a + b)\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Consider the following psuedocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check to see if projection is needed (how to determine?)\n",
    "\n",
    "# --- If projection is needed:\n",
    "\n",
    "    # --- Account for potential change in feature map depth\n",
    "\n",
    "    # --- Account for potential change in feature map size (subsample)\n",
    "\n",
    "    # --- Modify kernel_size if needed\n",
    "\n",
    "    # --- Perform projection\n",
    "\n",
    "# --- Perform residual operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a general method to facilitate an Inception module for any given single input tensor. Allow for the total number of output feature maps (after concatenation) to be determined dynamically as an argument for the method. Assume that the number of feature maps for each of the four Inception **paths** to yield an equal number of channels.\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(a, filters):\n",
    "    \"\"\"\n",
    "    Method to implement Inception module\n",
    "    \n",
    "      p1 = 1 x 1 conv\n",
    "      p2 = BN > 3 x 3 conv\n",
    "      p3 = BN > 5 x 5 conv\n",
    "      p4 = 3 x 3 pool > BN\n",
    "      \n",
    "      BN = bottleneck operation\n",
    "    \n",
    "    :return\n",
    "    \n",
    "      (tf.Tensor) None * i * j * c tensor\n",
    "      \n",
    "        i == a.shape[1]\n",
    "        j == a.shape[2]\n",
    "        c == filters\n",
    "        \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Use the template code from above. The only minor modification that needs to be made is to automatically account for number of output filters in each individual pathway to yield a concatenated filter that is the desired output shape.\n",
    "\n",
    "Consider the following pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Defiine lambda functions for: conv, proj, norm, relu, pool\n",
    "\n",
    "# --- Define 1x1, 3x3 and 5x5 convs\n",
    "\n",
    "# --- Define requisite filter size for each individual path\n",
    "\n",
    "# --- Define four different paths\n",
    "\n",
    "# --- Create bottlenecked operations\n",
    "\n",
    "# --- Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Create a general method to facilitate an SE module for any given single input tensor. Allow for the relative amount of compression performed prior to excitation  be determined dynamically as an argument for the method.\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se(a, r=4):\n",
    "    \"\"\"\n",
    "    Method to implement squeeze-and-exication module\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (int) r  : scalar to compress representation\n",
    "      \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Consider the following pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Squeeze (global pool)\n",
    "\n",
    "# --- Excitation (reduce channels to 1 / R)\n",
    "\n",
    "# --- Scale (expand channels to original size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
