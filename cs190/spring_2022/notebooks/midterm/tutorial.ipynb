{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will explore a few of the advanced approaches to customize a segmentation algorithm for medical imaging. These approaches will build upon the standard U-Net contracting-expanding CNN architecture. As in the prior tutorial, the goal remains to perform kidney segmentation on CT.\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about the KiTS Challenge can be found here: https://kits21.kits-challenge.org/. In this exercise, we will use this dataset to derive a model for slice-by-slice kidney segmentation. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='ct/kits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality. As needed, pass any custom configurations (e.g. batch size, normalization parameters, etc) into the optional `configs` dictionary argument. \n",
    "\n",
    "In this tutorial, we will be using abdominal CT volumes that have been preprocessed into 96 x 96 x 96 matrix volumes, each cropped to the right and left kidney, facilitating ease of algorithm training within the Google Colab platform. Based on model implementation strategy, both 2D and 3D data have been prepared for this exercise. To specificy the correct Generator template file, pass a designated `keyword` string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2D dataset**: To select the 2D data of input size `(1, 96, 96, 1)` use the keyword `2d-bin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d-bin', custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D dataset**: To select the 3D data of input size `(96, 96, 96, 1)` use the keyword `3d-bin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='3d-bin', custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created generators yield a total of `batch['size']` training samples based on the specified batch size. As before, each iteration yields dictionary of model inputs, `xs`. In the current example, there is just a single input image `xs['dat']` and a single target `xs['lbl']`. Let us examine the generator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, _ = next(gen_train)\n",
    "\n",
    "# --- Print dict keys\n",
    "for k, v in xs.items():\n",
    "    print('key = {} : shape = {}'.format(k.ljust(7), v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD5ejoTbx1_0"
   },
   "source": [
    "### KITS Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to visualize using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show the first example\n",
    "imshow(xs['dat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kidney masks\n",
    "\n",
    "The ground-truth labels are binary masks of the same matrix shape as the model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xs['lbl'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `imshow(...)` method to visualize the ground-truth tumor mask labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show tumor masks overlaid on original data\n",
    "imshow(xs['dat'][0], xs['lbl'][0])\n",
    "\n",
    "# --- Show tumor masks isolated\n",
    "imshow(xs['lbl'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Models\n",
    "\n",
    "Many medical imaging modalities yield 3D volume datasets. Full 3D CNN models implemented with 3D convolutional and convolutional transpose operations can process native 3D datasets and learn hierarchial 3D features. \n",
    "\n",
    "Given that we have *already* started to use `layers.Conv3D` and `layers.Conv3DTranspose` in our code, the choice between 2D and 3D operations requires only changing the kernel size and stride of certain model layers:\n",
    "\n",
    "* kernel size: `(3, 3, 3)`, instead of `(1, 3, 3)`\n",
    "* stride: `(2, 2, 2)`, instead of `(1, 2, 2)` (only when subsampling is requires, otherwise still `1`)\n",
    "\n",
    "Use the follow block to define 3D convolutional blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs\n",
    "kwargs = {\n",
    "    'kernel_size': (3, 3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2, 2))))\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(2, 2, 2))))\n",
    "\n",
    "concat = lambda a, b : layers.Concatenate()([a, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard 3D U-Net series of contracting layers can be defined as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model input \n",
    "x = Input(shape=(96, 96, 96, 1), dtype='float32')\n",
    "\n",
    "# --- Define contracting layers\n",
    "l1 = conv1(8, x)\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Connections\n",
    "\n",
    "A key component of the contracting-expanding segmentation architectures is the use of connections to combine both low- and high-level features. In addition to the standard **concatenation** operation, several variations can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual connection\n",
    "\n",
    "If *SAME* padding is used throughout the network architecture, and if the number of filters used at each block is symmetric, then the corresponding contracting and expanding layers should have exactly the same feature map size. In this scenario, a **residual** (addition) operation can be used instead of the standard concatenation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Use residual connections\n",
    "l6 = tran2(48, l5)\n",
    "l7 = tran2(32, conv1(48, l6 + l4))\n",
    "l8 = tran2(16, conv1(32, l7 + l3))\n",
    "l9 = tran2(8,  conv1(16, l8 + l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the advantages or disadvantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple operations\n",
    "\n",
    "As discussed in the lecture, high-resolution but shallow layers in the contracting arm of the network may sometimes be too \"raw\" and thus introduce noise into the network predictions. To help overcome this effect, consider the use of additional operations to refine the shallow contracting layers **prior** to combination with the expanding arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Use multiple operations\n",
    "l6 = tran2(48, l5)\n",
    "l7 = tran2(32, conv1(48, l6 + conv1(48, l4)))\n",
    "l8 = tran2(16, conv1(32, l7 + conv1(32, l3)))\n",
    "l9 = tran2(8,  conv1(16, l8 + conv1(16, l2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the advantages or disadvantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Supervision\n",
    "\n",
    "Multi-Resolution U-Net\n",
    "\n",
    "```\n",
    "[ input ]  -------- [ logits  ] ---> loss-00\n",
    "\n",
    "   ||                   /\\\n",
    "   \\/                   ||\n",
    "   \n",
    "[  L-1  ]  ------>  [ L-(n-1) ] ---> loss-01 (subsampled 1/2)\n",
    "\n",
    "   ||                   /\\\n",
    "   \\/                   ||\n",
    "   \n",
    "[  L-2  ]  ------>  [ L-(n-2) ] ---> loss-02 (subsampled 1/4)\n",
    "\n",
    "   ||                   /\\\n",
    "   \\/                   ||\n",
    "   \n",
    "[  L-3  ]  ------>  [ L-(n-3) ] ---> loss-03 (subsampled 1/8)\n",
    "\n",
    "   ||                   /\\\n",
    "   \\/                   ||\n",
    "   \n",
    "   ...                 ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model input \n",
    "x = Input(shape=(96, 96, 96, 1), dtype='float32')\n",
    "\n",
    "# --- Define contracting layers\n",
    "l1 = conv1(8, x)\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))\n",
    "\n",
    "# --- Define expanding layers\n",
    "l6  = tran2(48, l5)\n",
    "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
    "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
    "l9  = conv1(8, tran2(8,  conv1(16, concat(l2, l8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = layers.Conv3D(filters=2, **kwargs)(l9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deeply supervised U-Net creates a series of predictions at different resolutions:\n",
    "\n",
    "* `c0`: original resolution (96)\n",
    "* `c1`: subsampled by 1/2 (48)\n",
    "* `c2`: subsampled by 1/4 (24)\n",
    "* ... and so on.\n",
    "\n",
    "To produce these multi-resolution logit scores, consider a dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create logits\n",
    "logits = {\n",
    "    'c0': layers.Conv3D(filters=2, **kwargs)(l9),\n",
    "    'c1': layers.Conv3D(filters=2, **kwargs)(l8),\n",
    "    # ... what other layers can be added?\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a backbone model with these multi-resolution outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model\n",
    "backbone = Model(inputs=x, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define inputs\n",
    "inputs = {\n",
    "    'dat': Input(shape=(96, 96, 96, 1), name='dat'),\n",
    "    'lbl': Input(shape=(96, 96, 96, 1), name='lbl')}\n",
    "\n",
    "# --- Define first step of new wrapper model\n",
    "logits = backbone(inputs['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, importantly, each of different logit scores you created above must be matched to a subsampled version of the ground-truth segmentation mask, `inputs['lbl']`. To do this, consider simply serial application of the `MaxPool` operation; compared to a naive resampling operation, this ensures that as your prediction becomes smaller, the original target foreground does not disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = {}\n",
    "true = inputs['lbl']\n",
    "\n",
    "for c in sorted(logits.keys()):\n",
    "    \n",
    "    # --- Subsample ground-truth label if needed\n",
    "    if c != 'c0':\n",
    "        true = layers.MaxPooling3D(pool_size=(2, 2, 2))(true)\n",
    "    \n",
    "    # --- Create loss at current resolution\n",
    "    loss[c] = losses.SparseCategoricalCrossentropy(from_logits=True)(\n",
    "        y_true=true,\n",
    "        y_pred=logits[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Dice score metric\n",
    " \n",
    "The standard metric for spatial overlap is known as the **Dice score**. The Dice score is not a default metric built in the Tensorflow library, and thus we will define it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dsc(y_true, y_pred, c=1):\n",
    "    \"\"\"\n",
    "    Method to calculate the Dice score coefficient for given class\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      y_true : ground-truth label\n",
    "      y_pred : predicted logits scores\n",
    "           c : class to calculate DSC on\n",
    "    \n",
    "    \"\"\"    \n",
    "    true = y_true[..., 0] == c\n",
    "    pred = tf.math.argmax(y_pred, axis=-1) == c \n",
    "\n",
    "    A = tf.math.count_nonzero(true & pred) * 2\n",
    "    B = tf.math.count_nonzero(true) + tf.math.count_nonzero(pred)\n",
    "    \n",
    "    return tf.math.divide_no_nan(\n",
    "        tf.cast(A, tf.float32), \n",
    "        tf.cast(B, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Dice score\n",
    "dsc = calculate_dsc(y_true=inputs['lbl'], y_pred=logits['c0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model\n",
    "\n",
    "Now let us create the new wrapper model. The inputs are defined above already in our `inputs` Python dictionary. As outputs, let us return both the `logits` tensor as well as the `loss`. We will name this new wrapper model `training` because it will be used for training only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = Model(inputs=inputs, outputs={**logits, **loss, **{'dsc': dsc}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the `loss` and `metric` tensorws we defined above to the new `training` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add loss\n",
    "for l in loss.values():\n",
    "    training.add_loss(l)\n",
    "\n",
    "# --- Add metric\n",
    "training.add_metric(dsc, name='dsc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model\n",
    "\n",
    " To prepare the model for learning, a graph must be **compiled** with a strategy for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define an Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=2e-4)\n",
    "\n",
    "# --- Compile model\n",
    "training.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory data\n",
    "\n",
    "For moderate sized datasets which are too large to fit into immediate hard-drive cache, but small enough to fit into RAM memory, it is often times a good idea to first load all training data into RAM memory for increased speed of training. The `client` can be used for this purpose as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model\n",
    "training.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=100, \n",
    "    epochs=10,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=100,\n",
    "    validation_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Use the following lines of code to run prediction through the **valid** cohort generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "dsc = []\n",
    "\n",
    "for x, _ in test_valid:\n",
    "    \n",
    "    # --- Predict\n",
    "    outputs = training.predict(x)\n",
    "\n",
    "    # --- Argmax\n",
    "    dsc.append(outputs['dsc'])\n",
    "\n",
    "dsc = np.array(dsc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
